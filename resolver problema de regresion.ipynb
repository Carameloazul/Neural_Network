{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panda as pd \n",
    "import numpy as np \n",
    "from keras.datasets import boston_housing\n",
    "from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "La unidades en las etiquetas(labels) están dividas entre 1000(1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se resta el promedio y se divide entre la desviación estandar para normalizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis = 0)\n",
    "train_data = train_data - mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data = train_data/std\n",
    "\n",
    "# Por cuestiones de etiquetas, el modelo nunca debe saber otra información que no sea la del dataset\n",
    "# de entrenamiento, por eso se le resta y se divide al dataset de prueba el mismo promedio y std\n",
    "test_data = test_data - mean\n",
    "test_data = test_data / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error es la métrica de éxito para este modelo de regression y el Mean Square Error como función de pérdida\n",
    "En la última capa no se utiliza ningún tipo de función porque ser un modelo de regressión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_regression(input_data,lr_var = 0.001):\n",
    "    model.add(layers.Dense(64, activation = 'relu', input_shape = (input_data,)))\n",
    "    model.add(layers.Dense(64, activation = 'relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(\n",
    "            optimizers = optimizers.RMSprop(lr_var ),\n",
    "            loss = 'mse',\n",
    "            metrics = ['mae']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold es un método para dividir los datos en diferente cantidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epoch = 500\n",
    "all_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "    print('Fold:', i)\n",
    "    val_data = train_data[i*num_val_samples : (i + 1) * num_val_samples]\n",
    "    val_targets = train_labels[i*num_val_samples : (i + 1) * num_val_samples]\n",
    "\n",
    "    partia_train_data = pd.concatenate([train_data[:i * num_val_samples],\n",
    "                                        train_data[(i+1) * num_val_samples],\n",
    "                                        ],\n",
    "                                        axis = 0\n",
    "                                        )\n",
    "    partia_train_targets = pd.concatenate([train_labels[:i * num_val_samples],\n",
    "                                        train_labels[(i+1) * num_val_samples],\n",
    "                                        ],\n",
    "                                        axis = 0\n",
    "                                        )\n",
    "    \n",
    "    model = build_model_regression(0.001,13)\n",
    "\n",
    "    history = model.fit(\n",
    "        partia_train_data,\n",
    "        partia_train_targets,\n",
    "        epochs = num_epoch, \n",
    "        batch_size = 16,\n",
    "        validation_data = (val_data,val_targets),\n",
    "        verbose = 0\n",
    "    )\n",
    "    all_history.append(history.history['val_mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiene 80 Resultados por la cantidad de épocas que tuvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_history[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creando un Dataframe con all_history y hayando el promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mea_avg = pd.DataFrame(all_history).mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.plot(range(1, len(all_mea_avg[15:]) + 1),all_mea_avg[15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data, test_labels)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
